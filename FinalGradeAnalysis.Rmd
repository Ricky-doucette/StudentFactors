---
title: "Regression analysis to determine significant predictors in estimating students'
  final grade"
author: "Ricky Doucette"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```
# Attributes for both student-mat.csv (Math course) and student-por.csv (Portuguese language course) datasets:
1 school - student's school (binary: "GP" - Gabriel Pereira or "MS" - Mousinho da Silveira). 
2 sex - student's sex (binary: "F" - female or "M" - male)  
3 age - student's age (numeric: from 15 to 22)   
4 address - student's home address type.  (binary: "U" - urban or "R" - rural)  
5 famsize - family size (binary: "LE3" - less or equal to 3 or "GT3" - greater than 3)  
6 Pstatus - parent's cohabitation status   (binary: "T" - living together or "A" - apart)  
7 Medu - mother's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)  
8 Fedu - father's education (numeric: 0 - none,  1 - primary education (4th grade), 2 – 5th to 9th grade, 3 – secondary education or 4 – higher education)  
9 Mjob - mother's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")  
10 Fjob - father's job (nominal: "teacher", "health" care related, civil "services" (e.g. administrative or police), "at_home" or "other")  
11 reason - reason to choose this school (nominal: close to "home", school "reputation", "course" preference or "other")  
12 guardian - student's guardian (nominal: "mother", "father" or "other")  
13 traveltime - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)  
14 studytime - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)  
15 failures - number of past class failures (numeric: n if 1<=n<3, else 4)  
16 schoolsup - extra educational support (binary: yes or no). 
17 famsup - family educational support (binary: yes or no)  
18 paid - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)  
19 activities - extra-curricular activities (binary: yes or no)  
20 nursery - attended nursery school (binary: yes or no)  
21 higher - wants to take higher education (binary: yes or no). 
22 internet - Internet access at home (binary: yes or no). 
23 romantic - with a romantic relationship (binary: yes or no). 
24 famrel - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)  
25 freetime - free time after school (numeric: from 1 - very low to 5 - very high)  
26 goout - going out with friends (numeric: from 1 - very low to 5 - very high)  
27 Dalc - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)  
28 Walc - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)  
29 health - current health status (numeric: from 1 - very bad to 5 - very good)  
30 absences - number of school absences (numeric: from 0 to 93)  

### these grades are related with the course subject, Math or Portuguese:
31 G1 - first period grade (numeric: from 0 to 20)  
31 G2 - second period grade (numeric: from 0 to 20)  
32 G3 - final grade (numeric: from 0 to 20, output target)  

Additional note: there are several (382) students that belong to both datasets . 
These students can be identified by searching for identical attributes
that characterize each student, as shown in the annexed R file.

```{r}
#load dataset 
mydata <- read.csv("student-por.csv", sep=";", header = TRUE)

```


```{r}
# G3 is being set to a categorical variable. 0 if <10 (fail), 1 if >=10 (pass)
mydata['G3'][mydata['G3']<10] <- 0
mydata['G3'][mydata['G3']>=10] <- 1

# Removing points that are problematic in the graphs
mydata <- mydata[-647,]
mydata <- mydata[-1,]
```


```{r}
attach(mydata)

#Remove outlier rows 
# mydata <- mydata[!mydata$G3 == 0, ]
# mydata <- mydata[!mydata$G2 == 0, ]
# mydata <- mydata[!mydata$G1 == 0, ]
# mydata <- mydata[!mydata$G3 == 1,]

# Compute the correlation matrix
# Testing multicolinearity
#change data to factors

cols_to_factor <- c("school", "sex", "address", "famsize", "Pstatus",
                    "Mjob", "Fjob", "reason", "guardian", "schoolsup",
                    "famsup","paid","activities",
                    "nursery","higher","internet", "romantic")

# Use lapply to apply as.factor() to each column
mydata[, cols_to_factor] <- lapply(mydata[, cols_to_factor], as.factor)


```



```{r}
# Converting factor variables to numeric
mydata_numeric <- data.frame(lapply(mydata, function(x) {
  if(is.factor(x)) {
    as.numeric(as.character(x))
  } else {
    x
  }
}))
corr_matrix <- cor(mydata_numeric)
# Visualize the correlation matrix as a heatmap
library(ggplot2)
library(reshape2)
ggplot(melt(corr_matrix), aes(x=Var1, y=Var2, fill=value)) + 
  geom_tile() + 
  scale_fill_gradient2(low="blue", mid="white", high="red", 
                       midpoint=0, limit=c(-1,1), space="Lab", 
                       name="Pearson\nCorrelation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90))

# Using VIF to test for multicolinearity

library(car)
vif_model <- glm(G3 ~ ., data = mydata, family = "binomial")
vif(vif_model)

model <- glm(G3 ~ ., data = mydata, family = "binomial")
model
summary(model)
colnames(mydata)
```
Remove column G2 due to multicolinearity
```{r}
mydata <- mydata[, -32]
#fit full model again 
model <- glm(G3 ~ ., data = mydata, family = "binomial")
summary(model)
```




### model selection using stepwise forward selection with BIC, k =log(n) 

```{r}

model.empty <- glm(G3~1,data=mydata, family = "binomial")
model.step.bic <- step(model.empty,
direction = "forward",scope = list(lower = model.empty, upper = model), k=2.8, trace =1)
```




### model selection using stepwise forward selection with AIC, k = 2

```{r}

model.empty <- glm(G3~1,data=mydata, family = "binomial")
model.step.aic <- step(model.empty,
direction = "forward",scope = list(lower = model.empty, upper = model), k=2, trace =1)

#library(bestglm)
#model.bestglm.bic <- bestglm(mydata,IC = 'BIC') #subset regression BIC
#model.bestglm.bic$BestModels
```



### model selection using stepwise backward selection 

```{r}
model_full <- glm(G3 ~ ., data = mydata, family = "binomial")
model_backward <- step(model_full, direction = "backward", trace =1)

```


cannot use best subset as p > 15
```{r}
library(glmnet)
lambda.seq <- 10^seq(-2, 5, by = .1)
X <- data.matrix(mydata[,-length(mydata)])
y <- mydata[,length(mydata)]
cv.lasso <- cv.glmnet(X, y,
lambda = lambda.seq,
alpha = 1, #Lasso penalty
family = 'binomial')
plot(cv.lasso)
coef(cv.lasso, s = "lambda.min")
```





```{r}
#reload dataset 
mydata <- read.csv("student-por.csv", sep=";", header = TRUE)

```

```{r}
# G3 is being set to a categorical variable. 0 if <10 (fail), 1 if >=10 (pass)
mydata['G3'][mydata['G3']<10] <- 0
mydata['G3'][mydata['G3']>=10] <- 1

# Removing points that are problematic in the graphs
mydata <- mydata[-647,]
mydata <- mydata[-1,]

```


```{r}
attach(mydata)

#Remove outlier rows 
# mydata <- mydata[!mydata$G3 == 0, ]
# mydata <- mydata[!mydata$G2 == 0, ]
# mydata <- mydata[!mydata$G1 == 0, ]
# mydata <- mydata[!mydata$G3 == 1,]

# Compute the correlation matrix
# Testing multicolinearity
#change data to factors

cols_to_factor <- c("school", "sex", "address", "famsize", "Pstatus",
                    "Mjob", "Fjob", "reason", "guardian", "schoolsup",
                    "famsup","paid","activities",
                    "nursery","higher","internet", "romantic")

# Use lapply to apply as.factor() to each column
mydata[, cols_to_factor] <- lapply(mydata[, cols_to_factor], as.factor)


```



```{r}
lassofit <- glm(G3 ~ G2 + G1 + Walc + famrel + romantic + activities + failures, data=mydata, family = "binomial")

forwardfit <- glm (G3 ~ G2 + famrel + absences + G1 + age + activities + Walc + 
    romantic + school, data= mydata, family = "binomial")

summary(lassofit)
summary(forwardfit)


plot(forwardfit)
plot(lassofit)

rom <- ifelse(romantic=="yes",1,0)
act<- ifelse(activities=="yes",1,0)
scoo <- ifelse(school =="GP",1,0)

lassoLogit <- exp(coef(lassofit)[1] + G2*coef(lassofit)[2] + G1*coef(lassofit)[3] + Walc*coef(lassofit)[4] + famrel*coef(lassofit)[5] + rom*coef(lassofit)[6] + act*coef(lassofit)[7] + failures*coef(lassofit)[8])  / (1+exp(coef(lassofit)[1] + G2*coef(lassofit)[2] + G1*coef(lassofit)[3] + Walc*coef(lassofit)[4] + famrel*coef(lassofit)[5] + rom*coef(lassofit)[6] + act*coef(lassofit)[7] + failures*coef(lassofit)[8]))

forwardLogit <- exp(coef(forwardfit)[1] + G2*coef(forwardfit)[2] + famrel*coef(forwardfit)[3] + absences*coef(forwardfit)[4] + G1*coef(forwardfit)[5] + age*coef(forwardfit)[6] + act*coef(forwardfit)[7] + Walc*coef(forwardfit)[8] + rom*coef(forwardfit)[9]+ scoo*coef(forwardfit)[10])  / (1+exp(coef(forwardfit)[1] + G2*coef(forwardfit)[2] + famrel*coef(forwardfit)[3] + absences*coef(forwardfit)[4] + G1*coef(forwardfit)[5] + age*coef(forwardfit)[6] + act*coef(forwardfit)[7] + Walc*coef(forwardfit)[8] + rom*coef(forwardfit)[9]+ scoo*coef(forwardfit)[10]))


#plotting inverse logit
plot(lm(lassoLogit~ G2 + G1 + Walc + famrel + romantic + activities + failures))
plot(lm (forwardLogit ~ G2 + famrel + absences + G1 + age + activities + Walc + romantic + school))




#performing log transformations as the plots for the forwardfit and lassofit violates linear assumptions

# mydata$G3_log <- log(mydata$G3)
# fit1 <- glm(G3_log ~ G1 + G2+ Walc + famrel + romantic + activities + failures, data = mydata)
# fit2 <- glm (G3_log ~ G2 + famrel + absences + G1 + age + activities + Walc + romantic + school, data = mydata)
# 
# 
# fit_log <- glm(fit2)
# 
# summary(fit_log)
# 
# plot(fit_log)



```


removing G2 due to high multicolinearity 

```{r}
lassofit <- glm(G3 ~  G1 + Walc + famrel + romantic + activities + failures, family = "binomial")
forwardfit <- glm (G3 ~  famrel + absences + G1 + age + activities + Walc + 
    romantic + school, family = "binomial")
summary(lassofit)
summary(forwardfit)

plot(forwardfit)
plot(lassofit)

lassoLogit <- exp(coef(lassofit)[1] + G1*coef(lassofit)[2] + Walc*coef(lassofit)[3] + famrel*coef(lassofit)[4] + rom*coef(lassofit)[5] + act*coef(lassofit)[6] + failures*coef(lassofit)[7])  / (1+exp(coef(lassofit)[1] + G1*coef(lassofit)[2] + Walc*coef(lassofit)[3] + famrel*coef(lassofit)[4] + rom*coef(lassofit)[5] + act*coef(lassofit)[6] + failures*coef(lassofit)[7]))

forwardLogit <- exp(coef(forwardfit)[1] + famrel*coef(forwardfit)[2] + absences*coef(forwardfit)[3] + G1*coef(forwardfit)[4] + age*coef(forwardfit)[5] + act*coef(forwardfit)[6] + Walc*coef(forwardfit)[7] + rom*coef(forwardfit)[8]+ scoo*coef(forwardfit)[9])  / (1+exp(coef(forwardfit)[1] + famrel*coef(forwardfit)[2] + absences*coef(forwardfit)[3] + G1*coef(forwardfit)[4] + age*coef(forwardfit)[5] + act*coef(forwardfit)[6] + Walc*coef(forwardfit)[7] + rom*coef(forwardfit)[8]+ scoo*coef(forwardfit)[9]))

#plotting inverse logit
plot(lm(lassoLogit~ G2 + G1 + Walc + famrel + romantic + activities + failures))
plot(lm (forwardLogit ~ G2 + famrel + absences + G1 + age + activities + Walc + romantic + school))

#performing log transformations as the plots for the forwardfit and lassofit violates linear assumptions

# mydata$G3_log <- log(mydata$G3)
# fit1 <- glm(G3_log ~  Walc + famrel + romantic + activities + failures, data = mydata)
# fit2 <- glm (G3_log ~ famrel + absences + G1 + age + activities + Walc + romantic + school, data = mydata)
# 
# 
# fit_log <- glm(fit2)
# 
# summary(fit_log)
# 
# plot(fit_log)


vif(forwardfit)
```








